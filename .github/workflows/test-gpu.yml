name: Tests (GPU / CUDA)

# Triggered manually so you can pick the ref and runner.
# Requires a self-hosted runner labelled "gpu" with an NVIDIA GPU and the
# vllm extra dependencies pre-installed (CUDA toolkit, cuDNN, etc.).
#
# To register a runner:
#   GitHub repo → Settings → Actions → Runners → New self-hosted runner
#   Add the labels: self-hosted, Linux, gpu
on:
  workflow_dispatch:
    inputs:
      ref:
        description: "Branch, tag, or SHA to test"
        required: false
        default: "main"
      python-version:
        description: "Python version"
        required: false
        default: "3.12"

jobs:
  test-gpu:
    name: pytest -m cuda (GPU)
    runs-on: [self-hosted, Linux, gpu]

    steps:
      - uses: actions/checkout@v6
        with:
          ref: ${{ github.event.inputs.ref || github.ref }}

      - name: Set up Python ${{ github.event.inputs.python-version }}
        uses: actions/setup-python@v6
        with:
          python-version: ${{ github.event.inputs.python-version }}

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          enable-cache: true

      - name: Install dependencies (vllm extra)
        run: |
          uv sync --extra vllm --extra dev

      - name: Verify CUDA is available
        run: |
          uv run python -c "import torch; assert torch.cuda.is_available(), 'CUDA not found'"

      - name: Run GPU tests
        run: |
          uv run pytest tests/ -m cuda -v --tb=short
